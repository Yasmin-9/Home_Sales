# Home_Sales

The purpose of this challenge is to use SparkSQL to determine key metrics about home sales data. Spark was also used to create temporary views, partition the data, cache and uncache a temporary table, and verify that the table has been uncached. Thr run time was determined and compared when querying cached, unacached, and partitioned data. 

The code for this challenge was run on Google Colab, as approved by instructor, and can be found in the Home_Sales_colab.ipynb file. 
